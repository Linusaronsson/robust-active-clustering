{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "            transforms.RandomCrop(32, padding=4),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "        ])\n",
    "\n",
    "batch_size = 128\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='../datasets/cifar10_original_data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "#trainset.data = trainset.data[:]\n",
    "#trainset.targets = trainset.targets[:]\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='../datasets/cifar10_original_data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "import numpy as np\n",
    "X_train = trainset.data\n",
    "y_train = np.array(trainset.targets)\n",
    "X_test = testset.data\n",
    "y_test = np.array(testset.targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = None\n",
    "\n",
    "batch_size = 128\n",
    "\n",
    "trainset = torchvision.datasets.FashionMNIST(root='../datasets/fashion_mnist_data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "#trainset.data = trainset.data[:]\n",
    "#trainset.targets = trainset.targets[:]\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.FashionMNIST(root='../datasets/fashion_mnist_data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "X_train = trainset.data\n",
    "y_train = np.array(trainset.targets)\n",
    "X_test = testset.data\n",
    "y_test = np.array(testset.targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.save('../datasets/cifar10_original_data/X_train.npy', X_train)\n",
    "#np.save('../datasets/cifar10_original_data/Y_train.npy', y_train)\n",
    "#np.save('../datasets/cifar10_original_data/X_test.npy', X_test)\n",
    "#np.save('../datasets/cifar10_original_data/Y_test.npy', y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000,)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 32, 3)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, TensorDataset\n",
    "class CustomTensorDataset(Dataset):\n",
    "    \"\"\"TensorDataset with support of transforms.\n",
    "    \"\"\"\n",
    "    def __init__(self, x, y, transform=None):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        x = self.x[index]\n",
    "\n",
    "        if self.transform:\n",
    "            x = self.transform(x)\n",
    "\n",
    "        y = self.y[index]\n",
    "\n",
    "        return x, y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_data_sample(X, Y, size, rs):\n",
    "    if size <= 1:\n",
    "        num_samples = int(len(Y)*size)\n",
    "    else:\n",
    "        num_samples = np.minimum(size, len(Y))\n",
    "    inds = rs.choice(len(Y), num_samples)\n",
    "    return X[inds], Y[inds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.load(\"../datasets/mnist_data/full_train_data.npy\")\n",
    "y_train = np.load(\"../datasets/mnist_data/full_train_data_labels.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "X_train = np.load(\"../datasets/mnist_data/X_full.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60000, 28, 28])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40000, 32, 32, 3) (40000,)\n",
      "(10000, 32, 32, 3) (10000,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2000, 28, 28]) (2000,)\n",
      "torch.Size([2000, 28, 28]) (2000,)\n"
     ]
    }
   ],
   "source": [
    "rs = np.random.RandomState(19)\n",
    "X_train, y_train = random_data_sample(X_train, y_train, 2000, rs)\n",
    "X_test, y_test = random_data_sample(X_test, y_test, 2000, rs)\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform1 = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "transform2 = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "trainset = CustomTensorDataset(X_train, y_train, transform=transform1)\n",
    "testset = CustomTensorDataset(X_test, y_test, transform=transform2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, TensorDataset\n",
    "transform1 = transforms.Compose([\n",
    "            transforms.ToPILImage(),\n",
    "            transforms.RandomCrop(32, padding=4),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "        ])\n",
    "\n",
    "transform2 = transforms.Compose([\n",
    "            #transforms.ToPILImage(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "        ])\n",
    "\n",
    "trainset = CustomTensorDataset(X_train, y_train, transform=transform1)\n",
    "testset = CustomTensorDataset(X_test, y_test, transform=transform2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fashion mnist\n",
    "transform1 = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.286,), (0.3529,))\n",
    "])\n",
    "transform2 = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.286,), (0.3529,))\n",
    "])\n",
    "trainset = CustomTensorDataset(X_train, y_train, transform=transform1)\n",
    "testset = CustomTensorDataset(X_test, y_test, transform=transform2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rac.utils.models import cifar10net, resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "#model1 = cifar10net.CifarNet().to(device)\n",
    "resnet_model = resnet.ResNet18(num_classes=10, channels=1).to(device)\n",
    "#criterion = nn.CrossEntropyLoss()\n",
    "#optimizer = optim.Adam(resnet_model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training..\n",
      "Epoch: 43 Training accuracy: 0.969\n"
     ]
    }
   ],
   "source": [
    "from rac.utils.train_helper import data_train\n",
    "args = {'n_epoch':50, 'lr':float(0.001), 'batch_size':64, 'max_accuracy':1.1, 'optimizer':'adam'} \n",
    "dt = data_train(trainset, resnet_model, args)\n",
    "clf = dt.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.812"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt.get_acc_on_set(testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "loss:  1.6301084482456412\n",
      "1\n",
      "loss:  1.2052332870185833\n",
      "2\n",
      "loss:  0.9880083224657551\n",
      "3\n",
      "loss:  0.8417643240040831\n",
      "4\n",
      "loss:  0.7413882800685171\n",
      "5\n",
      "loss:  0.6650938836052595\n",
      "6\n",
      "loss:  0.604618360624289\n",
      "7\n",
      "loss:  0.5501956445024446\n",
      "8\n",
      "loss:  0.511761770376464\n",
      "9\n",
      "loss:  0.4791406128565064\n",
      "10\n",
      "loss:  0.448650045620511\n",
      "11\n",
      "loss:  0.4191503155490626\n",
      "12\n",
      "loss:  0.39869052968214236\n",
      "13\n",
      "loss:  0.37352940455422073\n",
      "14\n",
      "loss:  0.35493854000745223\n",
      "15\n",
      "loss:  0.3374041950001436\n",
      "16\n",
      "loss:  0.3185030119422147\n",
      "17\n",
      "loss:  0.3074923846346643\n",
      "18\n",
      "loss:  0.29109362434700625\n",
      "19\n",
      "loss:  0.27397948099524166\n",
      "20\n",
      "loss:  0.26201940350749\n",
      "21\n",
      "loss:  0.2489969413489332\n",
      "22\n",
      "loss:  0.23962745028536034\n",
      "23\n",
      "loss:  0.23146832682897367\n",
      "24\n",
      "loss:  0.21733764987772383\n",
      "25\n",
      "loss:  0.20742623692811907\n",
      "26\n",
      "loss:  0.20030033636047406\n",
      "27\n",
      "loss:  0.18682997904317764\n",
      "28\n",
      "loss:  0.18573372923504666\n",
      "29\n",
      "loss:  0.175299566725026\n",
      "30\n",
      "loss:  0.1690196701708962\n",
      "31\n",
      "loss:  0.15615444054917607\n",
      "32\n",
      "loss:  0.1543192547338698\n",
      "33\n",
      "loss:  0.14599033137378487\n",
      "34\n",
      "loss:  0.14007118296668963\n",
      "35\n",
      "loss:  0.1335184655683425\n",
      "36\n",
      "loss:  0.12994377198807724\n",
      "37\n",
      "loss:  0.12373485995451812\n",
      "38\n",
      "loss:  0.11422562247613811\n",
      "39\n",
      "loss:  0.1102676513364248\n",
      "40\n",
      "loss:  0.10766127151544289\n",
      "41\n",
      "loss:  0.10430653388028407\n",
      "42\n",
      "loss:  0.1009536170260147\n",
      "43\n",
      "loss:  0.09494099409683891\n",
      "44\n",
      "loss:  0.08710823429133886\n",
      "45\n",
      "loss:  0.08495972156905762\n",
      "46\n",
      "loss:  0.08029368923276739\n",
      "47\n",
      "loss:  0.07891051308311464\n",
      "48\n",
      "loss:  0.08169751377095041\n",
      "49\n",
      "loss:  0.07102582360262913\n",
      "50\n",
      "loss:  0.06940534059196482\n",
      "51\n",
      "loss:  0.06845944669440655\n",
      "52\n",
      "loss:  0.06289650799225435\n",
      "53\n",
      "loss:  0.06306246913197781\n",
      "54\n",
      "loss:  0.06243744577564623\n",
      "55\n",
      "loss:  0.05812565699133955\n",
      "56\n",
      "loss:  0.05873311508227797\n",
      "57\n",
      "loss:  0.056579186800209916\n",
      "58\n",
      "loss:  0.05353362699899146\n",
      "59\n",
      "loss:  0.049227725103487975\n",
      "60\n",
      "loss:  0.04861593391636715\n",
      "61\n",
      "loss:  0.04832709277801387\n",
      "62\n",
      "loss:  0.04371171186456595\n",
      "63\n",
      "loss:  0.04334865640277219\n",
      "64\n",
      "loss:  0.039614087597126396\n",
      "65\n",
      "loss:  0.040636235216865914\n",
      "66\n",
      "loss:  0.03789713295817356\n",
      "67\n",
      "loss:  0.03745356136504227\n",
      "68\n",
      "loss:  0.03287324194481973\n",
      "69\n",
      "loss:  0.033602733552084325\n",
      "70\n",
      "loss:  0.03408577763404021\n",
      "71\n",
      "loss:  0.033774434335772756\n",
      "72\n",
      "loss:  0.03397915867524093\n",
      "73\n",
      "loss:  0.03237476626701672\n",
      "74\n",
      "loss:  0.03067910725094826\n",
      "75\n",
      "loss:  0.031350728068405484\n",
      "76\n",
      "loss:  0.02837682511333538\n",
      "77\n",
      "loss:  0.028827085607516033\n",
      "78\n",
      "loss:  0.026513889692175913\n",
      "79\n",
      "loss:  0.026065996295148434\n",
      "80\n",
      "loss:  0.02567391928054316\n",
      "81\n",
      "loss:  0.025150197050760468\n",
      "82\n",
      "loss:  0.022739087556288732\n",
      "83\n",
      "loss:  0.02230079326858444\n",
      "84\n",
      "loss:  0.023770896841764755\n",
      "85\n",
      "loss:  0.022788148914949725\n",
      "86\n",
      "loss:  0.023218925714211733\n",
      "87\n",
      "loss:  0.019458880458953682\n",
      "88\n",
      "loss:  0.019547304690248617\n",
      "89\n",
      "loss:  0.02604198545340182\n",
      "90\n",
      "loss:  0.02153521234019543\n",
      "91\n",
      "loss:  0.021251234569220002\n",
      "92\n",
      "loss:  0.019800662378068355\n",
      "93\n",
      "loss:  0.022228252803049315\n",
      "94\n",
      "loss:  0.018226894009929828\n",
      "95\n",
      "loss:  0.016598714841589274\n",
      "96\n",
      "loss:  0.01565210180907317\n",
      "97\n",
      "loss:  0.014584958126061046\n",
      "98\n",
      "loss:  0.015773169134798294\n",
      "99\n",
      "loss:  0.015137449003663152\n",
      "100\n",
      "loss:  0.01835030424372886\n",
      "101\n",
      "loss:  0.018159427022968737\n",
      "102\n",
      "loss:  0.014527243466692312\n",
      "103\n",
      "loss:  0.015832070095400275\n",
      "104\n",
      "loss:  0.014090110352524863\n",
      "105\n",
      "loss:  0.014113261749672578\n",
      "106\n",
      "loss:  0.014556970891972665\n",
      "107\n",
      "loss:  0.013004126996361672\n",
      "108\n",
      "loss:  0.015280753554528594\n",
      "109\n",
      "loss:  0.013276966533425938\n",
      "110\n",
      "loss:  0.013410567985493284\n",
      "111\n",
      "loss:  0.013537977059619486\n",
      "112\n",
      "loss:  0.012936711503380953\n",
      "113\n",
      "loss:  0.0108053823834752\n",
      "114\n",
      "loss:  0.011447834545675583\n",
      "115\n",
      "loss:  0.011401392996672642\n",
      "116\n",
      "loss:  0.010993967281298382\n",
      "117\n",
      "loss:  0.011887919537879675\n",
      "118\n",
      "loss:  0.011502417604676555\n",
      "119\n",
      "loss:  0.010493351785374371\n",
      "120\n",
      "loss:  0.011576858188142962\n",
      "121\n",
      "loss:  0.00809249164768235\n",
      "122\n",
      "loss:  0.008532202703377489\n",
      "123\n",
      "loss:  0.009235446293251183\n",
      "124\n",
      "loss:  0.008307148322827466\n",
      "125\n",
      "loss:  0.00843860720750391\n",
      "126\n",
      "loss:  0.008286745482868136\n",
      "127\n",
      "loss:  0.009138973654218643\n",
      "128\n",
      "loss:  0.008085022600407265\n",
      "129\n",
      "loss:  0.008905796914251552\n",
      "130\n",
      "loss:  0.011554386891463958\n",
      "131\n",
      "loss:  0.008384988510735866\n",
      "132\n",
      "loss:  0.008101118941884547\n",
      "133\n",
      "loss:  0.007094409253806723\n",
      "134\n",
      "loss:  0.00944389024166726\n",
      "135\n",
      "loss:  0.008371739280651278\n",
      "136\n",
      "loss:  0.00989240816819048\n",
      "137\n",
      "loss:  0.007611511282169062\n",
      "138\n",
      "loss:  0.009477220428296212\n",
      "139\n",
      "loss:  0.011107322123066029\n",
      "140\n",
      "loss:  0.008293829072648517\n",
      "141\n",
      "loss:  0.01036898318901146\n",
      "142\n",
      "loss:  0.009395323540343095\n",
      "143\n",
      "loss:  0.007082014324833089\n",
      "144\n",
      "loss:  0.008415607052021231\n",
      "145\n",
      "loss:  0.008587452206023596\n",
      "146\n",
      "loss:  0.006369910024277999\n",
      "147\n",
      "loss:  0.0066524992228451105\n",
      "148\n",
      "loss:  0.005569736126547113\n",
      "149\n",
      "loss:  0.005944117542926122\n",
      "150\n",
      "loss:  0.008781077761097057\n",
      "151\n",
      "loss:  0.006803525088373107\n",
      "152\n",
      "loss:  0.006717382525929007\n",
      "153\n",
      "loss:  0.007082232923926952\n",
      "154\n",
      "loss:  0.0055452811028658\n",
      "155\n",
      "loss:  0.006603969167783985\n",
      "156\n",
      "loss:  0.007222374339047296\n",
      "157\n",
      "loss:  0.006590273657888401\n",
      "158\n",
      "loss:  0.005455184235672831\n",
      "159\n",
      "loss:  0.006722030205358995\n",
      "160\n",
      "loss:  0.005846898990880955\n",
      "161\n",
      "loss:  0.006595451073312258\n",
      "162\n",
      "loss:  0.005555003557367312\n",
      "163\n",
      "loss:  0.005228826704689914\n",
      "164\n",
      "loss:  0.006111453775220606\n",
      "165\n",
      "loss:  0.00538709659754332\n",
      "166\n",
      "loss:  0.006200666054803402\n",
      "167\n",
      "loss:  0.005106226585836976\n",
      "168\n",
      "loss:  0.004591024556571482\n",
      "169\n",
      "loss:  0.0037765783233814597\n",
      "170\n",
      "loss:  0.00423505735274552\n",
      "171\n",
      "loss:  0.0054610300692431914\n",
      "172\n",
      "loss:  0.004245222283648881\n",
      "173\n",
      "loss:  0.004321654153744514\n",
      "174\n",
      "loss:  0.005009745879963254\n",
      "175\n",
      "loss:  0.006183708104027478\n",
      "176\n",
      "loss:  0.005623283728612098\n",
      "177\n",
      "loss:  0.00654362944886535\n",
      "178\n",
      "loss:  0.004993673691185444\n",
      "179\n",
      "loss:  0.004564970368532824\n",
      "180\n",
      "loss:  0.004254737412659726\n",
      "181\n",
      "loss:  0.005350398643271607\n",
      "182\n",
      "loss:  0.005024879540660945\n",
      "183\n",
      "loss:  0.0033560229296287786\n",
      "184\n",
      "loss:  0.004523851018992391\n",
      "185\n",
      "loss:  0.0049489251970972386\n",
      "186\n",
      "loss:  0.004639991602632325\n",
      "187\n",
      "loss:  0.004882782774456643\n",
      "188\n",
      "loss:  0.005005817205324034\n",
      "189\n",
      "loss:  0.0049985628209241765\n",
      "190\n",
      "loss:  0.0064490326510756\n",
      "191\n",
      "loss:  0.0044335770127682085\n",
      "192\n",
      "loss:  0.0042582235484094596\n",
      "193\n",
      "loss:  0.003564247302353725\n",
      "194\n",
      "loss:  0.00361889219983011\n",
      "195\n",
      "loss:  0.0036801887230481357\n",
      "196\n",
      "loss:  0.0023750608931603734\n",
      "197\n",
      "loss:  0.0036310583073616057\n",
      "198\n",
      "loss:  0.002207307088876005\n",
      "199\n",
      "loss:  0.0037780955103989705\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(200):  # loop over the dataset multiple times\n",
    "    print(epoch)\n",
    "\n",
    "    running_loss = 0.0\n",
    "    step = 0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data[0].to(device), data[1].to(device),\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = resnet_model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        step += 1\n",
    "    print(\"loss: \", running_loss/step)\n",
    "    step = 0\n",
    "    running_loss = 0.0\n",
    "    acc = \n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 88 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "# since we're not training, we don't need to calculate the gradients for our outputs\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data[0].to(device), data[1].to(device)\n",
    "        # calculate outputs by running images through the network\n",
    "        outputs = resnet_model(images)\n",
    "        # the class with the highest energy is what we choose as prediction\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f'Accuracy of the network on the 10000 test images: {100 * correct // total} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "391"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trainloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding(model, dataset, dataloader, device=\"cuda\"):\n",
    "    # Ensure model is on right device and is in eval. mode\n",
    "    model.eval()\n",
    "    model = model.to(device)\n",
    "\n",
    "    # Create a tensor to hold embeddings\n",
    "    embedding = torch.zeros([len(dataset), model.get_embedding_dim()]).to(device)\n",
    "    evaluated_instances = 0\n",
    "    labels = []\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, data in enumerate(dataloader):\n",
    "            # Calculate softmax (probabilities) of predictions\n",
    "            x, y = data[0].to(device), data[1].to(device)\n",
    "            #out, l1 = model(elements_to_predict, return_embedding=True)\n",
    "            out, l1 = model(x, last=True)\n",
    "            labels.extend(y.tolist())\n",
    "            # Insert the calculated batch of probabilities into the tensor to return\n",
    "            #print(data)\n",
    "            l1 = torch.Tensor(l1)\n",
    "            start_slice = evaluated_instances\n",
    "            end_slice = start_slice + x.shape[0]\n",
    "            embedding[start_slice:end_slice] = l1\n",
    "            evaluated_instances = end_slice\n",
    "\n",
    "    return embedding, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_embedding, y_train_ = get_embedding(resnet_model, trainset, trainloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50000, 512])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_embedding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"../datasets/cifar10_data/cifar10_embedding.npy\", X_train_embedding.cpu().numpy())\n",
    "np.save(\"../datasets/cifar10_data/cifar10_embedding.npy\", y_train_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_test_embedding, y_test_ = get_embedding(resnet_model, testset, testloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.save(\"X_test_cifar.npy\", X_test_embedding.cpu().numpy())\n",
    "#np.save(\"Y_test_cifar.npy\", y_test_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
