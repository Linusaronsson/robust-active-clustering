{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from rac.pred_models import CustomTensorDataset, ACCNet\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "            transforms.RandomCrop(32, padding=4),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "        ])\n",
    "\n",
    "batch_size = 256\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='../datasets/cifar10_original_data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "#trainset.data = trainset.data\n",
    "#trainset.targets = trainset.targets\n",
    "X_train = trainset.data\n",
    "y_train = trainset.targets\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=8)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='../datasets/cifar10_original_data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=1024, num_workers=8)\n",
    "\n",
    "X_test = testset.data\n",
    "y_test = testset.targets\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clustering_from_clustering_solution(clustering_solution):\n",
    "    num_clusters = np.max(clustering_solution) + 1\n",
    "    clustering = [[] for _ in range(num_clusters)]\n",
    "    for i in range(len(clustering_solution)):\n",
    "        clustering[clustering_solution[i]].append(i)\n",
    "    return clustering, num_clusters\n",
    "\n",
    "def sim_matrix_from_clustering(clustering, N):\n",
    "    pairwise_similarities = -np.ones((N, N))\n",
    "    for cind in clustering:\n",
    "        pairwise_similarities[np.ix_(cind, cind)] = 1\n",
    "    return pairwise_similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sol = clustering_from_clustering_solution(y_train[:10000])\n",
    "train_sim_matrix = sim_matrix_from_clustering(train_sol[0], len(y_train[:10000]))\n",
    "\n",
    "test_sol = clustering_from_clustering_solution(y_test[:10000])\n",
    "test_sim_matrix = sim_matrix_from_clustering(test_sol[0], len(y_test[:10000]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 10000)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sim_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pairs(prop_pos, prop_neg, sim_matrix, data):\n",
    "    N = sim_matrix.shape[0]\n",
    "    lower_triangle_indices = np.tril_indices(N, -1)\n",
    "    ind_pos = np.where(sim_matrix[lower_triangle_indices] == 1)[0]\n",
    "    ind_neg = np.where(sim_matrix[lower_triangle_indices] == -1)[0]\n",
    "    num_pos = int(len(ind_pos)*prop_pos)\n",
    "    num_neg = int(len(ind_neg)*prop_neg)\n",
    "    print(\"num_pos: \", num_pos)\n",
    "    print(\"num_neg: \", num_neg)\n",
    "    ind_pos = np.random.choice(ind_pos, num_pos)\n",
    "    ind_neg = np.random.choice(ind_neg, num_neg)\n",
    "    if num_pos < num_neg:\n",
    "        indices = np.concatenate([ind_neg, ind_pos])\n",
    "    else:\n",
    "        indices = np.concatenate([ind_pos, ind_neg])\n",
    "    ind1, ind2 = lower_triangle_indices[0][indices], lower_triangle_indices[1][indices]\n",
    "    x1 = data[ind1]\n",
    "    x2 = data[ind2]\n",
    "    y = sim_matrix[ind1, ind2]\n",
    "    lab1 = np.where(y >= 0)\n",
    "    lab2 = np.where(y < 0)\n",
    "    y[lab1] = 1.0\n",
    "    y[lab2] = 0.0\n",
    "    return x1, x2, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_pos:  4998\n",
      "num_neg:  17998\n",
      "num_pos:  4995\n",
      "num_neg:  4500\n"
     ]
    }
   ],
   "source": [
    "x1_train, x2_train, y_train_pairs = get_pairs(0.001, 0.0004, train_sim_matrix, X_train)\n",
    "x1_test, x2_test, y_test_pairs = get_pairs(0.001, 0.0001, test_sim_matrix, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar_training_transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "])\n",
    "\n",
    "cifar_test_transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "])\n",
    "\n",
    "train_dataset = CustomTensorDataset(x1_train, x2_train, y_train_pairs, train=True, transform=cifar_training_transform)\n",
    "test_dataset = CustomTensorDataset(x1_test, x2_test, y_test_pairs, transform=cifar_test_transform)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "#class_sample_count = [10, 1, 20, 3, 4] # dataset has 10 class-1 samples, 1 class-2 samples, etc.\n",
    "class_sample_count = np.unique(y_train_pairs, return_counts=True)[1].tolist()\n",
    "#print(class_sample_count)\n",
    "weights = 1/torch.Tensor(class_sample_count)\n",
    "weights = weights[y_train_pairs]\n",
    "#print(weights)\n",
    "#sampler = torch.utils.data.sampler.WeightedRandomSampler(weights=weights, num_samples=len(weights), replacement=True)\n",
    "#train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, sampler=sampler)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, shuffle=False, batch_size=1024)\n",
    "#trainloader = data_utils.DataLoader(train_dataset, batch_size = batch_size, shuffle=True, sampler = sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for x1, x2, y in train_loader:\n",
    "    #print(np.unique(y, return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35996"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCEWithLogitsLoss()\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = ACCNet(base_net=\"resnet\", siamese=True).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training...\n",
      "35996\n",
      "0\n",
      "loss:  0.6636521120710669\n",
      "1\n",
      "loss:  0.602030305286661\n",
      "2\n",
      "loss:  0.5832869407089913\n",
      "3\n",
      "loss:  0.5674492982020038\n",
      "4\n",
      "loss:  0.55176590812405\n",
      "5\n",
      "loss:  0.5418877081345423\n",
      "6\n",
      "loss:  0.5316940339669275\n",
      "7\n",
      "loss:  0.5190746006182687\n",
      "8\n",
      "loss:  0.5022265020009212\n",
      "9\n",
      "loss:  0.4845648738791193\n",
      "10\n",
      "loss:  0.4698902180089805\n",
      "11\n",
      "loss:  0.45992514266380685\n",
      "12\n",
      "loss:  0.4456329881124204\n",
      "13\n",
      "loss:  0.4365959244459083\n",
      "14\n",
      "loss:  0.42705169012618344\n",
      "15\n",
      "loss:  0.4151002484988555\n",
      "16\n",
      "loss:  0.4040943309151104\n",
      "17\n",
      "loss:  0.39435345259591853\n",
      "18\n",
      "loss:  0.38349228858268425\n",
      "19\n",
      "loss:  0.37209667672908164\n",
      "20\n",
      "loss:  0.36453477311783206\n",
      "21\n",
      "loss:  0.3518229451667971\n",
      "22\n",
      "loss:  0.3455842712761126\n",
      "23\n",
      "loss:  0.34062823094737527\n",
      "24\n",
      "loss:  0.32656256066461653\n",
      "25\n",
      "loss:  0.3232939329971339\n",
      "26\n",
      "loss:  0.31074385995322745\n",
      "27\n",
      "loss:  0.30208116646842015\n",
      "28\n",
      "loss:  0.29555488604954366\n",
      "29\n",
      "loss:  0.2850794499565056\n",
      "30\n",
      "loss:  0.27975909086172973\n",
      "31\n",
      "loss:  0.27361189112919715\n",
      "32\n",
      "loss:  0.26116069581189805\n",
      "33\n",
      "loss:  0.25699897244004916\n",
      "34\n",
      "loss:  0.24135906738296503\n",
      "35\n",
      "loss:  0.2343508133392131\n",
      "36\n",
      "loss:  0.22158427557381455\n",
      "37\n",
      "loss:  0.2172964257716516\n",
      "38\n",
      "loss:  0.2039821922234196\n",
      "39\n",
      "loss:  0.19722886748215113\n",
      "40\n",
      "loss:  0.18449975983973052\n",
      "41\n",
      "loss:  0.18053442675222903\n",
      "42\n",
      "loss:  0.17071658037648924\n",
      "43\n",
      "loss:  0.15828279179755234\n",
      "44\n",
      "loss:  0.15868550692910438\n",
      "45\n",
      "loss:  0.14598360670787164\n",
      "46\n",
      "loss:  0.1382799735240702\n",
      "47\n",
      "loss:  0.13707193186201908\n",
      "48\n",
      "loss:  0.13063114547901394\n",
      "49\n",
      "loss:  0.12005732729581617\n",
      "50\n",
      "loss:  0.11498818962808259\n",
      "51\n",
      "loss:  0.11109426042638089\n",
      "52\n",
      "loss:  0.10697822204119459\n",
      "53\n",
      "loss:  0.1040337270917707\n",
      "54\n",
      "loss:  0.09779426576050192\n",
      "55\n",
      "loss:  0.09577133389096239\n",
      "56\n",
      "loss:  0.08997393776663665\n",
      "57\n",
      "loss:  0.08631357774417732\n",
      "58\n",
      "loss:  0.08413038310173175\n",
      "59\n",
      "loss:  0.08411523235867328\n",
      "60\n",
      "loss:  0.07626714254260333\n",
      "61\n",
      "loss:  0.07284036908323059\n",
      "62\n",
      "loss:  0.07418685581331609\n",
      "63\n",
      "loss:  0.07228546614813552\n",
      "64\n",
      "loss:  0.06660692672587386\n",
      "65\n",
      "loss:  0.06584814914444351\n",
      "66\n",
      "loss:  0.06020859642615786\n",
      "67\n",
      "loss:  0.05668077919323383\n",
      "68\n",
      "loss:  0.06171831094876022\n",
      "69\n",
      "loss:  0.059576932554623346\n",
      "70\n",
      "loss:  0.05742321515629637\n",
      "71\n",
      "loss:  0.05426791151460941\n",
      "72\n",
      "loss:  0.05191648893651478\n",
      "73\n",
      "loss:  0.05270369486379509\n",
      "74\n",
      "loss:  0.051218789516247705\n",
      "75\n",
      "loss:  0.04480182389439389\n",
      "76\n",
      "loss:  0.043848666703834735\n",
      "77\n",
      "loss:  0.04328378542439652\n",
      "78\n",
      "loss:  0.04242121435474722\n",
      "79\n",
      "loss:  0.04159831989423078\n",
      "80\n",
      "loss:  0.04454163153774486\n",
      "81\n",
      "loss:  0.0428541266499213\n",
      "82\n",
      "loss:  0.04037236586375366\n",
      "83\n",
      "loss:  0.03812916256625148\n",
      "84\n",
      "loss:  0.036493943957115416\n",
      "85\n",
      "loss:  0.03750001384197349\n",
      "86\n",
      "loss:  0.03737830997988171\n",
      "87\n",
      "loss:  0.03420116863395973\n",
      "88\n",
      "loss:  0.0360601289489191\n",
      "89\n",
      "loss:  0.03487546071506963\n",
      "90\n",
      "loss:  0.03286172942583449\n",
      "91\n",
      "loss:  0.03120852546848822\n",
      "92\n",
      "loss:  0.033265604788536435\n",
      "93\n",
      "loss:  0.02938637638876196\n",
      "94\n",
      "loss:  0.030193706055994224\n",
      "95\n",
      "loss:  0.030869129731022182\n",
      "96\n",
      "loss:  0.030004942544006645\n",
      "97\n",
      "loss:  0.030138100228607412\n",
      "98\n",
      "loss:  0.024910036747624462\n",
      "99\n",
      "loss:  0.026639538166857237\n",
      "100\n",
      "loss:  0.02967799391201955\n",
      "101\n",
      "loss:  0.02636083288149268\n",
      "102\n",
      "loss:  0.029492604544655195\n",
      "103\n",
      "loss:  0.02884272249706412\n",
      "104\n",
      "loss:  0.023279733061848884\n",
      "105\n",
      "loss:  0.024528766319389377\n",
      "106\n",
      "loss:  0.026181170748398923\n",
      "107\n",
      "loss:  0.024265506385138212\n",
      "108\n",
      "loss:  0.024528051596118407\n",
      "109\n",
      "loss:  0.025109446141673104\n",
      "110\n",
      "loss:  0.019667594287422614\n",
      "111\n",
      "loss:  0.021821330832566745\n",
      "112\n",
      "loss:  0.02075736708369075\n",
      "113\n",
      "loss:  0.023787757809815457\n",
      "114\n",
      "loss:  0.023186183228908863\n",
      "115\n",
      "loss:  0.018132622010146645\n",
      "116\n",
      "loss:  0.02230463087826905\n",
      "117\n",
      "loss:  0.024846715829009203\n",
      "118\n",
      "loss:  0.01986155723727562\n",
      "119\n",
      "loss:  0.021167761291987146\n",
      "120\n",
      "loss:  0.021737440779215193\n",
      "121\n",
      "loss:  0.01846523084101329\n",
      "122\n",
      "loss:  0.022831986250593815\n",
      "123\n",
      "loss:  0.018067491667849815\n",
      "124\n",
      "loss:  0.020377131794955074\n",
      "125\n",
      "loss:  0.0215310565046395\n",
      "126\n",
      "loss:  0.020753605356987646\n",
      "127\n",
      "loss:  0.01728010890188194\n",
      "128\n",
      "loss:  0.018251248415693352\n",
      "129\n",
      "loss:  0.018318941070412664\n",
      "130\n",
      "loss:  0.021409676821394292\n",
      "131\n",
      "loss:  0.017387753225190893\n",
      "132\n",
      "loss:  0.020540491754015528\n",
      "133\n",
      "loss:  0.01640777720184924\n",
      "134\n",
      "loss:  0.015917623634509995\n",
      "135\n",
      "loss:  0.020365321135216035\n",
      "136\n",
      "loss:  0.01653799263795857\n",
      "137\n",
      "loss:  0.018881856969652177\n",
      "138\n",
      "loss:  0.013803613416491996\n",
      "139\n",
      "loss:  0.015036720416404728\n",
      "140\n",
      "loss:  0.016795814889281675\n",
      "141\n",
      "loss:  0.01673201169317965\n",
      "142\n",
      "loss:  0.014670440073442597\n",
      "143\n",
      "loss:  0.015614216600232766\n",
      "144\n",
      "loss:  0.016458644569715276\n",
      "145\n",
      "loss:  0.014248524941239515\n",
      "146\n",
      "loss:  0.017460920587740566\n",
      "147\n",
      "loss:  0.014996008616931534\n",
      "148\n",
      "loss:  0.0166034148290611\n",
      "149\n",
      "loss:  0.014306003890216914\n",
      "150\n",
      "loss:  0.014398540583890744\n",
      "151\n",
      "loss:  0.012081409381138586\n",
      "152\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(net.parameters(), lr=0.0001)\n",
    "#optimizer = torch.optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "#optimizer = torch.optim.SGD(net.parameters(), lr=0.0005, momentum=0.9)\n",
    "#optimizer = torch.optim.SGD(net.parameters(), lr=0.0005, momentum=0.9, weight_decay=5e-4)\n",
    "print(\"training...\")\n",
    "print(len(train_dataset))\n",
    "for epoch in range(300):  # loop over the dataset multiple times\n",
    "    print(epoch)\n",
    "    running_loss = 0.0\n",
    "    step = 0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        #print(np.unique(data[2], return_counts=True))\n",
    "        #print(data[2])\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        x1, x2, labels = data[0].to(device), data[1].to(device), data[2].to(device)\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(x1, x2)\n",
    "        outputs = outputs.reshape((outputs.shape[0]))\n",
    "        #labels = labels.reshape((labels.shape[0], 1))\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        step += 1\n",
    "    print(\"loss: \", running_loss/step)\n",
    "    step = 0\n",
    "    running_loss = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "# since we're not training, we don't need to calculate the gradients for our outputs\n",
    "preds = []\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        x1, x2, labels = data[0].to(device), data[1].to(device), data[2].to(device)\n",
    "        # calculate outputs by running images through the network\n",
    "        outputs = net(x1, x2)\n",
    "        pred = nn.Sigmoid()(outputs)\n",
    "        #print(pred)\n",
    "        pred = pred.cpu().numpy()\n",
    "        pred = pred.reshape(pred.shape[0])\n",
    "        pred[pred >= 0.5] = 1\n",
    "        pred[pred < 0.5] = 0\n",
    "        #print(torch.max(pred.data, 1)[1])\n",
    "        # the class with the highest energy is what we choose as prediction\n",
    "        #_, predicted = torch.max(pred.data, 1)\n",
    "        preds.extend(pred.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9495"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0., 1.]), array([6497, 2998]))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(preds, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9495"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_test_pairs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0., 1.]), array([4500, 4995]))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_test_pairs, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.62      0.89      0.73      4500\n",
      "         1.0       0.83      0.50      0.62      4995\n",
      "\n",
      "    accuracy                           0.68      9495\n",
      "   macro avg       0.72      0.69      0.68      9495\n",
      "weighted avg       0.73      0.68      0.67      9495\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test_pairs, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "My Python",
   "language": "python",
   "name": "my_python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
