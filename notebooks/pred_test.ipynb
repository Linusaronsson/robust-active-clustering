{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from rac.pred_models import CustomTensorDataset, ACCNet\n",
    "import numpy as np\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "            transforms.RandomCrop(32, padding=4),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "        ])\n",
    "\n",
    "batch_size = 256\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='../datasets/cifar10_original_data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "#trainset.data = trainset.data\n",
    "#trainset.targets = trainset.targets\n",
    "X_train = trainset.data\n",
    "y_train = trainset.targets\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=8)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='../datasets/cifar10_original_data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=1024, num_workers=8)\n",
    "\n",
    "X_test = testset.data\n",
    "y_test = testset.targets\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "X_train = np.load(\"X_train_cifar.npy\")\n",
    "y_train = np.load(\"Y_train_cifar.npy\")\n",
    "X_test = np.load(\"X_test_cifar.npy\")\n",
    "y_test = np.load(\"Y_test_cifar.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X = np.load(\"../datasets/cifar10_data/cifar10_embedding.npy\")\n",
    "#Y = np.load(\"../datasets/cifar10_data/cifar10_labels.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn import preprocessing\n",
    "#X = preprocessing.StandardScaler().fit_transform(X)\n",
    "#from sklearn.decomposition import PCA\n",
    "#pca = PCA(n_components=100)\n",
    "#X = pca.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.model_selection import train_test_split\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clustering_from_clustering_solution(clustering_solution):\n",
    "    num_clusters = np.max(clustering_solution) + 1\n",
    "    clustering = [[] for _ in range(num_clusters)]\n",
    "    for i in range(len(clustering_solution)):\n",
    "        clustering[clustering_solution[i]].append(i)\n",
    "    return clustering, num_clusters\n",
    "\n",
    "def sim_matrix_from_clustering(clustering, N):\n",
    "    pairwise_similarities = -np.ones((N, N))\n",
    "    for cind in clustering:\n",
    "        pairwise_similarities[np.ix_(cind, cind)] = 1\n",
    "    return pairwise_similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sol = clustering_from_clustering_solution(y_train[:10000])\n",
    "train_sim_matrix = sim_matrix_from_clustering(train_sol[0], len(y_train[:10000]))\n",
    "\n",
    "test_sol = clustering_from_clustering_solution(y_test[:10000])\n",
    "test_sim_matrix = sim_matrix_from_clustering(test_sol[0], len(y_test[:10000]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 10000)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sim_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pairs(prop_pos, prop_neg, sim_matrix, data):\n",
    "    N = sim_matrix.shape[0]\n",
    "    lower_triangle_indices = np.tril_indices(N, -1)\n",
    "    ind_pos = np.where(sim_matrix[lower_triangle_indices] == 1)[0]\n",
    "    ind_neg = np.where(sim_matrix[lower_triangle_indices] == -1)[0]\n",
    "    num_pos = int(len(ind_pos)*prop_pos)\n",
    "    num_neg = int(len(ind_neg)*prop_neg)\n",
    "    print(\"num_pos: \", num_pos)\n",
    "    print(\"num_neg: \", num_neg)\n",
    "    ind_pos = np.random.choice(ind_pos, num_pos)\n",
    "    ind_neg = np.random.choice(ind_neg, num_neg)\n",
    "    if num_pos < num_neg:\n",
    "        indices = np.concatenate([ind_neg, ind_pos])\n",
    "    else:\n",
    "        indices = np.concatenate([ind_pos, ind_neg])\n",
    "    ind1, ind2 = lower_triangle_indices[0][indices], lower_triangle_indices[1][indices]\n",
    "    x1 = data[ind1]\n",
    "    x2 = data[ind2]\n",
    "    y = sim_matrix[ind1, ind2]\n",
    "    lab1 = np.where(y >= 0)\n",
    "    lab2 = np.where(y < 0)\n",
    "    y[lab1] = 1.0\n",
    "    y[lab2] = 0.0\n",
    "    return x1, x2, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_pos:  4996\n",
      "num_neg:  17999\n",
      "num_pos:  4995\n",
      "num_neg:  4500\n"
     ]
    }
   ],
   "source": [
    "x1_train, x2_train, y_train_pairs = get_pairs(0.001, 0.0004, train_sim_matrix, X_train)\n",
    "x1_test, x2_test, y_test_pairs = get_pairs(0.001, 0.0001, test_sim_matrix, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar_training_transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "])\n",
    "\n",
    "cifar_test_transform = transforms.Compose([\n",
    "    #transforms.ToPILImage(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "])\n",
    "\n",
    "train_dataset = CustomTensorDataset(x1_train, x2_train, y_train_pairs, train=True, transform=cifar_training_transform)\n",
    "test_dataset = CustomTensorDataset(x1_test, x2_test, y_test_pairs, transform=cifar_test_transform)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CustomTensorDataset(torch.Tensor(x1_train), torch.Tensor(x2_train), torch.Tensor(y_train_pairs), train=True, transform=None)\n",
    "test_dataset = CustomTensorDataset(torch.Tensor(x1_test), torch.Tensor(x2_test), torch.Tensor(y_test_pairs), transform=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "#class_sample_count = [10, 1, 20, 3, 4] # dataset has 10 class-1 samples, 1 class-2 samples, etc.\n",
    "class_sample_count = np.unique(y_train_pairs, return_counts=True)[1].tolist()\n",
    "#print(class_sample_count)\n",
    "weights = 1/torch.Tensor(class_sample_count)\n",
    "weights = weights[y_train_pairs]\n",
    "#print(weights)\n",
    "#sampler = torch.utils.data.sampler.WeightedRandomSampler(weights=weights, num_samples=len(weights), replacement=True)\n",
    "#train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, sampler=sampler)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, shuffle=False, batch_size=1024)\n",
    "#trainloader = data_utils.DataLoader(train_dataset, batch_size = batch_size, shuffle=True, sampler = sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for x1, x2, y in train_loader:\n",
    "    #print(np.unique(y, return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35998"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCEWithLogitsLoss()\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = ACCNet(base_net=\"three_layer_net\", siamese=True, input_dim=512).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training...\n",
      "35998\n",
      "0\n",
      "loss:  0.27280678057131613\n",
      "1\n",
      "loss:  0.04018638282518913\n",
      "2\n",
      "loss:  0.018802124435570857\n",
      "3\n",
      "loss:  0.011270246141737142\n",
      "4\n",
      "loss:  0.007788570391976915\n",
      "5\n",
      "loss:  0.00667369461528369\n",
      "6\n",
      "loss:  0.003019441327465911\n",
      "7\n",
      "loss:  0.0031338355776876358\n",
      "8\n",
      "loss:  0.0026594920304016845\n",
      "9\n",
      "loss:  0.0002779298639842772\n",
      "10\n",
      "loss:  0.0001228516807939947\n",
      "11\n",
      "loss:  5.746927079321754e-05\n",
      "12\n",
      "loss:  4.203114307801702e-05\n",
      "13\n",
      "loss:  3.2130345831490505e-05\n",
      "14\n",
      "loss:  2.6048067858251277e-05\n",
      "15\n",
      "loss:  2.18244759649909e-05\n",
      "16\n",
      "loss:  1.7593279361538774e-05\n",
      "17\n",
      "loss:  1.4529788384136072e-05\n",
      "18\n",
      "loss:  1.2143002431823772e-05\n",
      "19\n",
      "loss:  1.0069644046053547e-05\n",
      "20\n",
      "loss:  8.494534593925025e-06\n",
      "21\n",
      "loss:  7.36364170612656e-06\n",
      "22\n",
      "loss:  6.078499926906397e-06\n",
      "23\n",
      "loss:  4.987663891430042e-06\n",
      "24\n",
      "loss:  4.216642383759809e-06\n",
      "25\n",
      "loss:  3.620891990036682e-06\n",
      "26\n",
      "loss:  2.9944599567583163e-06\n",
      "27\n",
      "loss:  2.6346067505841523e-06\n",
      "28\n",
      "loss:  2.1429335418400617e-06\n",
      "29\n",
      "loss:  1.7942270459850445e-06\n",
      "30\n",
      "loss:  1.5529337161638976e-06\n",
      "31\n",
      "loss:  1.2896409903546317e-06\n",
      "32\n",
      "loss:  1.1088379467445562e-06\n",
      "33\n",
      "loss:  9.036918784478456e-07\n",
      "34\n",
      "loss:  7.849259094357357e-07\n",
      "35\n",
      "loss:  6.559773627723892e-07\n",
      "36\n",
      "loss:  5.585329182087648e-07\n",
      "37\n",
      "loss:  4.623739943836595e-07\n",
      "38\n",
      "loss:  3.9269926107434406e-07\n",
      "39\n",
      "loss:  3.4057383189903236e-07\n",
      "40\n",
      "loss:  2.8344865742647475e-07\n",
      "41\n",
      "loss:  2.3868760642365266e-07\n",
      "42\n",
      "loss:  2.0467586344667439e-07\n",
      "43\n",
      "loss:  1.7249088717588154e-07\n",
      "44\n",
      "loss:  1.4549415952757687e-07\n",
      "45\n",
      "loss:  1.2314473308802583e-07\n",
      "46\n",
      "loss:  1.0580242408191615e-07\n",
      "47\n",
      "loss:  8.991844887723966e-08\n",
      "48\n",
      "loss:  7.558543693207972e-08\n",
      "49\n",
      "loss:  6.574056962910286e-08\n",
      "50\n",
      "loss:  5.543509998065738e-08\n",
      "51\n",
      "loss:  4.7444716984539225e-08\n",
      "52\n",
      "loss:  4.0515752325804325e-08\n",
      "53\n",
      "loss:  3.499013910862406e-08\n",
      "54\n",
      "loss:  2.9653882844335317e-08\n",
      "55\n",
      "loss:  2.586013097829213e-08\n",
      "56\n",
      "loss:  2.1757256126568838e-08\n",
      "57\n",
      "loss:  1.838534706668095e-08\n",
      "58\n",
      "loss:  1.5677251021790425e-08\n",
      "59\n",
      "loss:  1.3562073436895317e-08\n",
      "60\n",
      "loss:  1.2031006810183441e-08\n",
      "61\n",
      "loss:  1.0320061128951615e-08\n",
      "62\n",
      "loss:  8.652709632522416e-09\n",
      "63\n",
      "loss:  7.506721358191376e-09\n",
      "64\n",
      "loss:  6.5927928165983294e-09\n",
      "65\n",
      "loss:  5.720916962184902e-09\n",
      "66\n",
      "loss:  4.795319204564978e-09\n",
      "67\n",
      "loss:  4.23388392410812e-09\n",
      "68\n",
      "loss:  3.582618955046401e-09\n",
      "69\n",
      "loss:  3.1836695415494516e-09\n",
      "70\n",
      "loss:  2.615628992750851e-09\n",
      "71\n",
      "loss:  2.3111328219594145e-09\n",
      "72\n",
      "loss:  1.9683269311145143e-09\n",
      "73\n",
      "loss:  1.7206347961874157e-09\n",
      "74\n",
      "loss:  1.5026657154594666e-09\n",
      "75\n",
      "loss:  1.3252080662143871e-09\n",
      "76\n",
      "loss:  1.1534748377097292e-09\n",
      "77\n",
      "loss:  9.90768619431856e-10\n",
      "78\n",
      "loss:  8.298237650613494e-10\n",
      "79\n",
      "loss:  6.977212881527824e-10\n",
      "80\n",
      "loss:  5.845534915060619e-10\n",
      "81\n",
      "loss:  4.788715054910726e-10\n",
      "82\n",
      "loss:  3.9630745356007525e-10\n",
      "83\n",
      "loss:  3.368613361067657e-10\n",
      "84\n",
      "loss:  2.873229048300584e-10\n",
      "85\n",
      "loss:  2.1796910001905834e-10\n",
      "86\n",
      "loss:  1.8494347877422403e-10\n",
      "87\n",
      "loss:  1.5191785772623777e-10\n",
      "88\n",
      "loss:  1.3870760922830406e-10\n",
      "89\n",
      "loss:  1.1889223608770737e-10\n",
      "90\n",
      "loss:  1.15589674160072e-10\n",
      "91\n",
      "loss:  1.131677954656322e-10\n",
      "92\n",
      "loss:  8.586661523656918e-11\n",
      "93\n",
      "loss:  6.60512424896686e-11\n",
      "94\n",
      "loss:  5.944611824070175e-11\n",
      "95\n",
      "loss:  6.274868036518517e-11\n",
      "96\n",
      "loss:  5.284099399173488e-11\n",
      "97\n",
      "loss:  3.632818336931773e-11\n",
      "98\n",
      "loss:  3.9630745493801164e-11\n",
      "99\n",
      "loss:  4.293330761828459e-11\n",
      "100\n",
      "loss:  3.632818336931773e-11\n",
      "101\n",
      "loss:  2.642049699586744e-11\n",
      "102\n",
      "loss:  2.972305912035087e-11\n",
      "103\n",
      "loss:  3.30256212448343e-11\n",
      "104\n",
      "loss:  2.972305912035087e-11\n",
      "105\n",
      "loss:  1.9815372746900582e-11\n",
      "106\n",
      "loss:  2.311793487138401e-11\n",
      "107\n",
      "loss:  2.311793487138401e-11\n",
      "108\n",
      "loss:  2.311793487138401e-11\n",
      "109\n",
      "loss:  1.321024849793372e-11\n",
      "110\n",
      "loss:  1.651281062241715e-11\n",
      "111\n",
      "loss:  1.651281062241715e-11\n",
      "112\n",
      "loss:  1.9815372746900582e-11\n",
      "113\n",
      "loss:  1.321024849793372e-11\n",
      "114\n",
      "loss:  1.9815372746900582e-11\n",
      "115\n",
      "loss:  1.321024849793372e-11\n",
      "116\n",
      "loss:  9.907686373450291e-12\n",
      "117\n",
      "loss:  1.651281062241715e-11\n",
      "118\n",
      "loss:  1.321024849793372e-11\n",
      "119\n",
      "loss:  1.321024849793372e-11\n",
      "120\n",
      "loss:  9.907686373450291e-12\n",
      "121\n",
      "loss:  6.60512424896686e-12\n",
      "122\n",
      "loss:  1.321024849793372e-11\n",
      "123\n",
      "loss:  6.60512424896686e-12\n",
      "124\n",
      "loss:  6.60512424896686e-12\n",
      "125\n",
      "loss:  9.907686373450291e-12\n",
      "126\n",
      "loss:  9.907686373450291e-12\n",
      "127\n",
      "loss:  1.321024849793372e-11\n",
      "128\n",
      "loss:  3.30256212448343e-12\n",
      "129\n",
      "loss:  1.321024849793372e-11\n",
      "130\n",
      "loss:  3.30256212448343e-12\n",
      "131\n",
      "loss:  6.60512424896686e-12\n",
      "132\n",
      "loss:  6.60512424896686e-12\n",
      "133\n",
      "loss:  6.60512424896686e-12\n",
      "134\n",
      "loss:  6.60512424896686e-12\n",
      "135\n",
      "loss:  9.907686373450291e-12\n",
      "136\n",
      "loss:  6.60512424896686e-12\n",
      "137\n",
      "loss:  3.30256212448343e-12\n",
      "138\n",
      "loss:  9.907686373450291e-12\n",
      "139\n",
      "loss:  3.30256212448343e-12\n",
      "140\n",
      "loss:  9.907686373450291e-12\n",
      "141\n",
      "loss:  3.30256212448343e-12\n",
      "142\n",
      "loss:  6.60512424896686e-12\n",
      "143\n",
      "loss:  6.60512424896686e-12\n",
      "144\n",
      "loss:  3.30256212448343e-12\n",
      "145\n",
      "loss:  6.60512424896686e-12\n",
      "146\n",
      "loss:  6.60512424896686e-12\n",
      "147\n",
      "loss:  0.0\n",
      "148\n",
      "loss:  9.907686373450291e-12\n",
      "149\n",
      "loss:  0.0\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(net.parameters(), lr=0.0001)\n",
    "#optimizer = torch.optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "#optimizer = torch.optim.SGD(net.parameters(), lr=0.0005, momentum=0.9)\n",
    "#optimizer = torch.optim.SGD(net.parameters(), lr=0.0005, momentum=0.9, weight_decay=5e-4)\n",
    "print(\"training...\")\n",
    "print(len(train_dataset))\n",
    "for epoch in range(150):  # loop over the dataset multiple times\n",
    "    print(epoch)\n",
    "    running_loss = 0.0\n",
    "    step = 0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        #print(np.unique(data[2], return_counts=True))\n",
    "        #print(data[2])\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        x1, x2, labels = data[0].to(device), data[1].to(device), data[2].to(device)\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(x1, x2)\n",
    "        outputs = outputs.reshape((outputs.shape[0]))\n",
    "        #labels = labels.reshape((labels.shape[0], 1))\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        step += 1\n",
    "    print(\"loss: \", running_loss/step)\n",
    "    step = 0\n",
    "    running_loss = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "# since we're not training, we don't need to calculate the gradients for our outputs\n",
    "preds = []\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        x1, x2, labels = data[0].to(device), data[1].to(device), data[2].to(device)\n",
    "        # calculate outputs by running images through the network\n",
    "        outputs = net(x1, x2)\n",
    "        pred = nn.Sigmoid()(outputs)\n",
    "        #print(pred)\n",
    "        pred = pred.cpu().numpy()\n",
    "        pred = pred.reshape(pred.shape[0])\n",
    "        pred[pred >= 0.5] = 1\n",
    "        pred[pred < 0.5] = 0\n",
    "        #print(torch.max(pred.data, 1)[1])\n",
    "        # the class with the highest energy is what we choose as prediction\n",
    "        #_, predicted = torch.max(pred.data, 1)\n",
    "        preds.extend(pred.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9495"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0., 1.]), array([5406, 4089]))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(preds, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9495"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_test_pairs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0., 1.]), array([4500, 4995]))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_test_pairs, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.82      0.98      0.89      4500\n",
      "         1.0       0.98      0.80      0.88      4995\n",
      "\n",
      "    accuracy                           0.89      9495\n",
      "   macro avg       0.90      0.89      0.89      9495\n",
      "weighted avg       0.90      0.89      0.89      9495\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test_pairs, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.81      0.98      0.88      4500\n",
      "         1.0       0.97      0.79      0.87      4995\n",
      "\n",
      "    accuracy                           0.88      9495\n",
      "   macro avg       0.89      0.88      0.88      9495\n",
      "weighted avg       0.89      0.88      0.88      9495\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test_pairs, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "My Python",
   "language": "python",
   "name": "my_python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
