{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from rac.pred_models import CustomTensorDataset, ACCNet\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "            transforms.RandomCrop(32, padding=4),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "        ])\n",
    "\n",
    "batch_size = 256\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='../datasets/cifar10_original_data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "#trainset.data = trainset.data\n",
    "#trainset.targets = trainset.targets\n",
    "X_train = trainset.data\n",
    "y_train = trainset.targets\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=8)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='../datasets/cifar10_original_data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=1024, num_workers=8)\n",
    "\n",
    "X_test = testset.data\n",
    "y_test = testset.targets\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clustering_from_clustering_solution(clustering_solution):\n",
    "    num_clusters = np.max(clustering_solution) + 1\n",
    "    clustering = [[] for _ in range(num_clusters)]\n",
    "    for i in range(len(clustering_solution)):\n",
    "        clustering[clustering_solution[i]].append(i)\n",
    "    return clustering, num_clusters\n",
    "\n",
    "def sim_matrix_from_clustering(clustering, N):\n",
    "    pairwise_similarities = -np.ones((N, N))\n",
    "    for cind in clustering:\n",
    "        pairwise_similarities[np.ix_(cind, cind)] = 1\n",
    "    return pairwise_similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sol = clustering_from_clustering_solution(y_train[:10000])\n",
    "train_sim_matrix = sim_matrix_from_clustering(train_sol[0], len(y_train[:10000]))\n",
    "\n",
    "test_sol = clustering_from_clustering_solution(y_test[:10000])\n",
    "test_sim_matrix = sim_matrix_from_clustering(test_sol[0], len(y_test[:10000]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 10000)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sim_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pairs(prop_pos, prop_neg, sim_matrix, data):\n",
    "    N = sim_matrix.shape[0]\n",
    "    lower_triangle_indices = np.tril_indices(N, -1)\n",
    "    ind_pos = np.where(sim_matrix[lower_triangle_indices] == 1)[0]\n",
    "    ind_neg = np.where(sim_matrix[lower_triangle_indices] == -1)[0]\n",
    "    num_pos = int(len(ind_pos)*prop_pos)\n",
    "    num_neg = int(len(ind_neg)*prop_neg)\n",
    "    print(\"num_pos: \", num_pos)\n",
    "    print(\"num_neg: \", num_neg)\n",
    "    ind_pos = np.random.choice(ind_pos, num_pos)\n",
    "    ind_neg = np.random.choice(ind_neg, num_neg)\n",
    "    if num_pos < num_neg:\n",
    "        indices = np.concatenate([ind_neg, ind_pos])\n",
    "    else:\n",
    "        indices = np.concatenate([ind_pos, ind_neg])\n",
    "    ind1, ind2 = lower_triangle_indices[0][indices], lower_triangle_indices[1][indices]\n",
    "    x1 = data[ind1]\n",
    "    x2 = data[ind2]\n",
    "    y = sim_matrix[ind1, ind2]\n",
    "    lab1 = np.where(y >= 0)\n",
    "    lab2 = np.where(y < 0)\n",
    "    y[lab1] = 1.0\n",
    "    y[lab2] = 0.0\n",
    "    return x1, x2, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_pos:  4998\n",
      "num_neg:  4499\n",
      "num_pos:  4995\n",
      "num_neg:  4500\n"
     ]
    }
   ],
   "source": [
    "x1_train, x2_train, y_train_pairs = get_pairs(0.001, 0.0001, train_sim_matrix, X_train)\n",
    "x1_test, x2_test, y_test_pairs = get_pairs(0.001, 0.0001, test_sim_matrix, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar_training_transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "])\n",
    "\n",
    "cifar_test_transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "])\n",
    "\n",
    "train_dataset = CustomTensorDataset(x1_train, x2_train, y_train_pairs, train=True, transform=cifar_training_transform)\n",
    "test_dataset = CustomTensorDataset(x1_test, x2_test, y_test_pairs, transform=cifar_test_transform)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "#class_sample_count = [10, 1, 20, 3, 4] # dataset has 10 class-1 samples, 1 class-2 samples, etc.\n",
    "class_sample_count = np.unique(y_train_pairs, return_counts=True)[1].tolist()\n",
    "#print(class_sample_count)\n",
    "weights = 1/torch.Tensor(class_sample_count)\n",
    "weights = weights[y_train_pairs]\n",
    "#print(weights)\n",
    "sampler = torch.utils.data.sampler.WeightedRandomSampler(weights=weights, num_samples=len(weights), replacement=True)\n",
    "#train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, sampler=sampler)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, shuffle=False, batch_size=1024)\n",
    "#trainloader = data_utils.DataLoader(train_dataset, batch_size = batch_size, shuffle=True, sampler = sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for x1, x2, y in train_loader:\n",
    "    #print(np.unique(y, return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9996"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCEWithLogitsLoss()\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = ACCNet(base_net=\"cifarnet\", siamese=True).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training...\n",
      "9996\n",
      "0\n",
      "loss:  0.6843304635076647\n",
      "1\n",
      "loss:  0.6386162334403961\n",
      "2\n",
      "loss:  0.6231420731244357\n",
      "3\n",
      "loss:  0.609805916228529\n",
      "4\n",
      "loss:  0.606425242678881\n",
      "5\n",
      "loss:  0.5904815750929883\n",
      "6\n",
      "loss:  0.5881493030973758\n",
      "7\n",
      "loss:  0.5852526525462127\n",
      "8\n",
      "loss:  0.5784019082738219\n",
      "9\n",
      "loss:  0.5902277527319201\n",
      "10\n",
      "loss:  0.5727088638744054\n",
      "11\n",
      "loss:  0.5648453886825386\n",
      "12\n",
      "loss:  0.5611587092401807\n",
      "13\n",
      "loss:  0.5563247169575909\n",
      "14\n",
      "loss:  0.5503553915507602\n",
      "15\n",
      "loss:  0.5489487216179137\n",
      "16\n",
      "loss:  0.5473278331478804\n",
      "17\n",
      "loss:  0.5405414676904667\n",
      "18\n",
      "loss:  0.5352632664921928\n",
      "19\n",
      "loss:  0.5389763195335486\n",
      "20\n",
      "loss:  0.530040903226168\n",
      "21\n",
      "loss:  0.5308943707497475\n",
      "22\n",
      "loss:  0.5199632485035247\n",
      "23\n",
      "loss:  0.5205940562799668\n",
      "24\n",
      "loss:  0.5190062355824421\n",
      "25\n",
      "loss:  0.51568994943145\n",
      "26\n",
      "loss:  0.5202168729010462\n",
      "27\n",
      "loss:  0.5106102217573942\n",
      "28\n",
      "loss:  0.5006278408157948\n",
      "29\n",
      "loss:  0.5050624808821825\n",
      "30\n",
      "loss:  0.49782417529568135\n",
      "31\n",
      "loss:  0.5007734862676031\n",
      "32\n",
      "loss:  0.5112086653492094\n",
      "33\n",
      "loss:  0.4812195099166937\n",
      "34\n",
      "loss:  0.4798261402593198\n",
      "35\n",
      "loss:  0.4828106397063601\n",
      "36\n",
      "loss:  0.477264439619121\n",
      "37\n",
      "loss:  0.4709011658060103\n",
      "38\n",
      "loss:  0.46749114464843505\n",
      "39\n",
      "loss:  0.46007614468722585\n",
      "40\n",
      "loss:  0.46763453101817004\n",
      "41\n",
      "loss:  0.45681345195385953\n",
      "42\n",
      "loss:  0.45635929719822393\n",
      "43\n",
      "loss:  0.44305205661533403\n",
      "44\n",
      "loss:  0.46619626910790884\n",
      "45\n",
      "loss:  0.4617867762798736\n",
      "46\n",
      "loss:  0.43745493567424676\n",
      "47\n",
      "loss:  0.4391517514192867\n",
      "48\n",
      "loss:  0.42731475586310036\n",
      "49\n",
      "loss:  0.4245846812851193\n",
      "50\n",
      "loss:  0.4430907336353373\n",
      "51\n",
      "loss:  0.4172501960743315\n",
      "52\n",
      "loss:  0.40577033282529723\n",
      "53\n",
      "loss:  0.4020116190756546\n",
      "54\n",
      "loss:  0.4023024258912975\n",
      "55\n",
      "loss:  0.4016106916674164\n",
      "56\n",
      "loss:  0.40000823307794775\n",
      "57\n",
      "loss:  0.4084856181520779\n",
      "58\n",
      "loss:  0.4134335920561532\n",
      "59\n",
      "loss:  0.41434103476290257\n",
      "60\n",
      "loss:  0.38389019668464647\n",
      "61\n",
      "loss:  0.38055463620541713\n",
      "62\n",
      "loss:  0.3788262835240529\n",
      "63\n",
      "loss:  0.4078577621393047\n",
      "64\n",
      "loss:  0.3747002013417141\n",
      "65\n",
      "loss:  0.3717059715465051\n",
      "66\n",
      "loss:  0.37322327256501714\n",
      "67\n",
      "loss:  0.3598082839386326\n",
      "68\n",
      "loss:  0.36429839155763577\n",
      "69\n",
      "loss:  0.35698200597608865\n",
      "70\n",
      "loss:  0.3585892638555639\n",
      "71\n",
      "loss:  0.40528732267219336\n",
      "72\n",
      "loss:  0.34838677568627047\n",
      "73\n",
      "loss:  0.33763952008553155\n",
      "74\n",
      "loss:  0.3321017024781861\n",
      "75\n",
      "loss:  0.33137138064529337\n",
      "76\n",
      "loss:  0.3231942737256157\n",
      "77\n",
      "loss:  0.3171058850488456\n",
      "78\n",
      "loss:  0.32458518336499054\n",
      "79\n",
      "loss:  0.34743466753473273\n",
      "80\n",
      "loss:  0.30156025737059367\n",
      "81\n",
      "loss:  0.31073870169324697\n",
      "82\n",
      "loss:  0.30304143281695195\n",
      "83\n",
      "loss:  0.3135368051410766\n",
      "84\n",
      "loss:  0.30139620086429575\n",
      "85\n",
      "loss:  0.30500452122596733\n",
      "86\n",
      "loss:  0.2812680694725931\n",
      "87\n",
      "loss:  0.2825757191797797\n",
      "88\n",
      "loss:  0.27932914691391175\n",
      "89\n",
      "loss:  0.27750740280378533\n",
      "90\n",
      "loss:  0.29017146532058546\n",
      "91\n",
      "loss:  0.2664835882007155\n",
      "92\n",
      "loss:  0.30435519950942286\n",
      "93\n",
      "loss:  0.2557984355610043\n",
      "94\n",
      "loss:  0.2542258287422343\n",
      "95\n",
      "loss:  0.27414464406273886\n",
      "96\n",
      "loss:  0.24157528892567637\n",
      "97\n",
      "loss:  0.2382325628440575\n",
      "98\n",
      "loss:  0.2344366607021469\n",
      "99\n",
      "loss:  0.2404529417941493\n",
      "100\n",
      "loss:  0.26881176687601377\n",
      "101\n",
      "loss:  0.25515913423762226\n",
      "102\n",
      "loss:  0.24505988230090156\n",
      "103\n",
      "loss:  0.2062089727003575\n",
      "104\n",
      "loss:  0.2003517293310218\n",
      "105\n",
      "loss:  0.1927566297684997\n",
      "106\n",
      "loss:  0.20531971750600855\n",
      "107\n",
      "loss:  0.2169422747075684\n",
      "108\n",
      "loss:  0.20507982123202204\n",
      "109\n",
      "loss:  0.2691524880065084\n",
      "110\n",
      "loss:  0.1956173150650671\n",
      "111\n",
      "loss:  0.20640067534728043\n",
      "112\n",
      "loss:  0.17383402528991787\n",
      "113\n",
      "loss:  0.17152426018667738\n",
      "114\n",
      "loss:  0.17357575734883712\n",
      "115\n",
      "loss:  0.17317328220688738\n",
      "116\n",
      "loss:  0.1658459769250177\n",
      "117\n",
      "loss:  0.14958807259356732\n",
      "118\n",
      "loss:  0.17934732239654166\n",
      "119\n",
      "loss:  0.18833390147024126\n",
      "120\n",
      "loss:  0.18503737928115246\n",
      "121\n",
      "loss:  0.15475230130688722\n",
      "122\n",
      "loss:  0.17579514631839724\n",
      "123\n",
      "loss:  0.1581378076746333\n",
      "124\n",
      "loss:  0.14311525338993256\n",
      "125\n",
      "loss:  0.13621389684799984\n",
      "126\n",
      "loss:  0.14707172583302838\n",
      "127\n",
      "loss:  0.14440224834802975\n",
      "128\n",
      "loss:  0.20157706351420496\n",
      "129\n",
      "loss:  0.145597560459968\n",
      "130\n",
      "loss:  0.15597014609332996\n",
      "131\n",
      "loss:  0.1506415436505031\n",
      "132\n",
      "loss:  0.12196001149830438\n",
      "133\n",
      "loss:  0.11518347803758314\n",
      "134\n",
      "loss:  0.12303174697275818\n",
      "135\n",
      "loss:  0.11507150455393834\n",
      "136\n",
      "loss:  0.13758613647944168\n",
      "137\n",
      "loss:  0.1500349106236524\n",
      "138\n",
      "loss:  0.14266293524892734\n",
      "139\n",
      "loss:  0.13761203287608323\n",
      "140\n",
      "loss:  0.11511254362155357\n",
      "141\n",
      "loss:  0.12276736256235835\n",
      "142\n",
      "loss:  0.09451121360706675\n",
      "143\n",
      "loss:  0.17556729437884167\n",
      "144\n",
      "loss:  0.11144853701685226\n",
      "145\n",
      "loss:  0.13067220413992015\n",
      "146\n",
      "loss:  0.11736056172374937\n",
      "147\n",
      "loss:  0.10446737028122431\n",
      "148\n",
      "loss:  0.12943757098217545\n",
      "149\n",
      "loss:  0.10785692445300549\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(net.parameters(), lr=0.0001)\n",
    "#optimizer = torch.optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "#optimizer = torch.optim.SGD(self.net.parameters(), lr=0.0005, momentum=0.9)\n",
    "#optimizer = torch.optim.SGD(net.parameters(), lr=0.0005, momentum=0.9, weight_decay=5e-4)\n",
    "print(\"training...\")\n",
    "print(len(train_dataset))\n",
    "for epoch in range(150):  # loop over the dataset multiple times\n",
    "    print(epoch)\n",
    "    running_loss = 0.0\n",
    "    step = 0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        #print(np.unique(data[2], return_counts=True))\n",
    "        #print(data[2])\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        x1, x2, labels = data[0].to(device), data[1].to(device), data[2].to(device)\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(x1, x2)\n",
    "        outputs = outputs.reshape((outputs.shape[0]))\n",
    "        #labels = labels.reshape((labels.shape[0], 1))\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        step += 1\n",
    "    print(\"loss: \", running_loss/step)\n",
    "    step = 0\n",
    "    running_loss = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "# since we're not training, we don't need to calculate the gradients for our outputs\n",
    "preds = []\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        x1, x2, labels = data[0].to(device), data[1].to(device), data[2].to(device)\n",
    "        # calculate outputs by running images through the network\n",
    "        outputs = net(x1, x2)\n",
    "        pred = nn.Sigmoid()(outputs)\n",
    "        #print(pred)\n",
    "        pred = pred.cpu().numpy()\n",
    "        pred = pred.reshape(pred.shape[0])\n",
    "        pred[pred >= 0.5] = 1\n",
    "        pred[pred < 0.5] = 0\n",
    "        #print(torch.max(pred.data, 1)[1])\n",
    "        # the class with the highest energy is what we choose as prediction\n",
    "        #_, predicted = torch.max(pred.data, 1)\n",
    "        preds.extend(pred.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9495"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0., 1.]), array([5090, 4405]))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(preds, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0., 1.]), array([4500, 4995]))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_test_pairs, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.64      0.72      0.68      4500\n",
      "         1.0       0.72      0.63      0.67      4995\n",
      "\n",
      "    accuracy                           0.68      9495\n",
      "   macro avg       0.68      0.68      0.68      9495\n",
      "weighted avg       0.68      0.68      0.68      9495\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test_pairs, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "My Python",
   "language": "python",
   "name": "my_python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
